{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch library\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "# Create a 2D tensor\n",
    "tensor = torch.tensor([[1, 2], [3, 4]])\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition:\n",
      " tensor([[2, 4],\n",
      "        [6, 8]])\n",
      "Element-wise Multiplication:\n",
      " tensor([[ 1,  4],\n",
      "        [ 9, 16]])\n",
      "Matrix Multiplication:\n",
      " tensor([[ 7, 10],\n",
      "        [15, 22]])\n"
     ]
    }
   ],
   "source": [
    "# Basic tensor operations\n",
    "tensor_add = tensor + tensor\n",
    "tensor_mul = tensor * tensor\n",
    "tensor_matmul = torch.matmul(tensor, tensor)\n",
    "\n",
    "print(\"Addition:\\n\", tensor_add)\n",
    "print(\"Element-wise Multiplication:\\n\", tensor_mul)\n",
    "print(\"Matrix Multiplication:\\n\", tensor_matmul)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of y with respect to x: tensor(4.)\n"
     ]
    }
   ],
   "source": [
    "# Enable gradient tracking\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "\n",
    "y = x**2\n",
    "\n",
    "# Compute gradients\n",
    "y.backward()\n",
    "\n",
    "# Access and print the gradient\n",
    "print(\"Gradient of y with respect to x:\", x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 6 samples\n",
      "\n",
      "\n",
      "Sample batch: \n",
      "\n",
      "X: tensor([[0.5000, 1.0000, 1.5000],\n",
      "        [3.5000, 4.0000, 4.5000]]) \n",
      "\n",
      "Y: tensor([2., 5.])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Generating a simple example dataset dataframe\n",
    "data = {\n",
    "    \"feature1\": [0.5, 1.5, 2.5, 3.5, 4.5, 6.0],\n",
    "    \"feature2\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0],\n",
    "    \"feature3\": [1.5, 2.5, 3.5, 4.5, 5.5, 7.0],\n",
    "    \"target\": [2.0, 3.0, 4.0, 5.0, 6.0, 7.0]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "        self.features = dataframe.drop(\"target\", axis=1).values\n",
    "        self.targets = dataframe[\"target\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        target = torch.tensor(self.targets[idx], dtype=torch.float32)\n",
    "        return features, target\n",
    "\n",
    "# Create an instance of the dataset\n",
    "dataset = CustomDataset(df)\n",
    "print(f\"The dataset has {len(dataset)} samples\")\n",
    "\n",
    "\n",
    "# Dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Checking one batch of the dataloader\n",
    "dataiter = iter(dataloader)\n",
    "sample_X, sample_y = next(dataiter)\n",
    "print(f\"\\n\\nSample batch: \\n\\nX: {sample_X} \\n\\nY: {sample_y}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (fc1): Linear(in_features=3, out_features=2, bias=True)\n",
      "  (fc2): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # Declaring the layers to use\n",
    "        self.fc1 = nn.Linear(3, 2)\n",
    "        self.fc2 = nn.Linear(2, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Defining the connections and data flow across layers in the model\n",
    "        # (2 inputs, 4 hidden neurons + ReLu, 1 output target)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the network\n",
    "model = SimpleNN()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Defining a Loss Function, we use the Mean Squared Error in this case\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Defining an Optimizer function, we use Stochastic Gradient Descent\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.005)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Epoch 1 ----\n",
      "Batch 1, Loss: 7.4690046310424805\n",
      "Batch 2, Loss: 17.65382194519043\n",
      "Batch 3, Loss: 26.777929306030273\n",
      "---- Epoch 2 ----\n",
      "Batch 1, Loss: 6.661708831787109\n",
      "Batch 2, Loss: 7.172825813293457\n",
      "Batch 3, Loss: 18.06693458557129\n",
      "---- Epoch 3 ----\n",
      "Batch 1, Loss: 3.8117458820343018\n",
      "Batch 2, Loss: 1.2558903694152832\n",
      "Batch 3, Loss: 0.6197564601898193\n",
      "---- Epoch 4 ----\n",
      "Batch 1, Loss: 0.1321382224559784\n",
      "Batch 2, Loss: 0.10426364839076996\n",
      "Batch 3, Loss: 0.071308434009552\n",
      "---- Epoch 5 ----\n",
      "Batch 1, Loss: 0.013189473189413548\n",
      "Batch 2, Loss: 0.24772098660469055\n",
      "Batch 3, Loss: 0.12977713346481323\n",
      "---- Epoch 6 ----\n",
      "Batch 1, Loss: 0.10149131715297699\n",
      "Batch 2, Loss: 0.031407617032527924\n",
      "Batch 3, Loss: 0.22959811985492706\n",
      "---- Epoch 7 ----\n",
      "Batch 1, Loss: 0.12110497057437897\n",
      "Batch 2, Loss: 0.0742880254983902\n",
      "Batch 3, Loss: 0.1561034917831421\n",
      "---- Epoch 8 ----\n",
      "Batch 1, Loss: 0.13337978720664978\n",
      "Batch 2, Loss: 0.19584670662879944\n",
      "Batch 3, Loss: 0.12535583972930908\n",
      "---- Epoch 9 ----\n",
      "Batch 1, Loss: 0.10472267866134644\n",
      "Batch 2, Loss: 0.11357322335243225\n",
      "Batch 3, Loss: 0.07514697313308716\n",
      "---- Epoch 10 ----\n",
      "Batch 1, Loss: 0.01294444315135479\n",
      "Batch 2, Loss: 0.22994564473628998\n",
      "Batch 3, Loss: 0.11055310815572739\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    print(f\"---- Epoch {epoch+1} ----\")\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = model(X).squeeze()  # Forward pass\n",
    "        loss = criterion(outputs, y)  # Compute loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        print(f\"Batch {batch+1}, Loss: {loss}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2080 Ti'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "New sample: tensor([2., 3., 3.], device='cuda:0')\n",
      "Prediction: tensor(3.1465, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Creating a new sample \n",
    "new_X = torch.tensor([2., 3., 3.])\n",
    "\n",
    "# Move tensor to GPU\n",
    "new_X = new_X.to(device)\n",
    "print(\"New sample:\", new_X)\n",
    "\n",
    "# Move model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Inference from GPU\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(new_X)\n",
    "    \n",
    "print(\"Prediction:\", pred[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n",
      "\n",
      "Prediction: tensor([5.2236], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alomg\\AppData\\Local\\Temp\\ipykernel_18200\\1619593817.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model.load_state_dict(torch.load(\"simple_nn.pth\"))\n"
     ]
    }
   ],
   "source": [
    "# Save the model as a compressed file\n",
    "torch.save(model.state_dict(), \"simple_nn.pth\")\n",
    "\n",
    "# Load the model\n",
    "loaded_model = SimpleNN()\n",
    "loaded_model.load_state_dict(torch.load(\"simple_nn.pth\"))\n",
    "print(\"Model loaded successfully\\n\")\n",
    "\n",
    "loaded_model.to(device)\n",
    "\n",
    "# Use the model to infer new samples\n",
    "new_X = torch.tensor([4., 4.5, 5.], dtype=torch.float32)\n",
    "new_X = new_X.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = loaded_model(new_X)\n",
    "    \n",
    "print(\"Prediction:\", pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
